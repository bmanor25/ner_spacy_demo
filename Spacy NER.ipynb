{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) withÂ Spacy\n",
    "\n",
    "The goal of this notebook is to show the full end to end process for Name-Entity Recognition([**NER**](https://nlp.stanford.edu/ner/)) with [**Spacy**](https://spacy.io/). We will also explore **pattern matching** as an alternative to **NER** when there is a known small set of fixed values. \n",
    "\n",
    "This will be a full end to end demo of the whole process where we will perform both labeling and model training.\n",
    "\n",
    "As an example, we will create a model to detect entities related to **oil/petrol** from this [public dataset](https://www.kaggle.com/mitusha/email-dataset) which contains a list of emails related to the oil industry. This is an oversimplification since you want to have more generic entities but this will provide a good example where pattern matching is a better option than NER. So, to summarize we are going to extract oil related entities from emails.\n",
    "\n",
    "We will perform the following:\n",
    "- Read the emails data set which has an email per line.\n",
    "- We will label the emails with the OIL entity using **[Doccano](http://doccano.herokuapp.com/)** labeling tool. This is a manual process.\n",
    "- We will save the labels in a text file as **JSONL**.\n",
    "- We will use **Spacy** Neural Network model to train a new statistical model. \n",
    "- We will save the model.\n",
    "- We will create a **Spacy** NLP pipeline and use the new model to detect oil entities never seen before.\n",
    "- Finally, we will use pattern matching instead of a deep learning model to compare both method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label the Data\n",
    "\n",
    "The first step is to label the entities using **Doccano**.\n",
    "\n",
    "Follow **[Doccano](https://doccano.github.io/doccano/tutorial/)** instructions to install and open Doccano.\n",
    "\n",
    "If you use **Linux/Mac**, I recommend using the docker image:\n",
    "- `docker pull doccano/doccano`\n",
    "- `docker container create --name doccano -e \"ADMIN_USERNAME=admin\" -e \"ADMIN_EMAIL=admin@example.com\" -e \"ADMIN_PASSWORD=password\" -p 8000:8000 doccano/doccano`\n",
    "- `docker container start doccano`\n",
    "    \n",
    "For **Windows**, just use **pip**: \n",
    "- `pip install doccano`\n",
    "- `doccano`\n",
    "\n",
    "Go to http://127.0.0.1:8000/.\n",
    "\n",
    "Next, label the data using Doccano. Find entities which talk about oil, petrol, petroleum, etc and label them with the tag **OIL**. \n",
    "\n",
    "Export the result as **JSONL(Text label)** format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "First, let's read the JSONL file using format:\n",
    "\n",
    "`{\"id\": 15, \"text\": \"....\", \"meta\": {}, \"annotation_approver\": null, \"labels\": [[226, 234, \"OIL\"]]}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "labeled_data = []\n",
    "with open(r\"emails_labeled.jsonl\", \"r\") as read_file:\n",
    "    for line in read_file:\n",
    "        data = json.loads(line)\n",
    "        labeled_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the format to spacy format\n",
    "\n",
    "Next, let's convert the Deccano format to Spacy format.\n",
    "\n",
    "We will also remove extra columns and rename labels to entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = []\n",
    "for entry in labeled_data:\n",
    "    entities = []\n",
    "    for e in entry['labels']:\n",
    "        entities.append((e[0], e[1],e[2]))\n",
    "    spacy_entry = (entry['text'], {\"entities\": entities})\n",
    "    TRAINING_DATA.append(spacy_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model!\n",
    "\n",
    "We use Deep Learning (NN) and set a dropout rate of 0.3 to prevent overfitting.\n",
    "\n",
    "The idea is to use a Neural Network with many neurons and several layers. We show them text that has been already labeled, so we know the correct answer. We will run several iterations and on each iteration we will calculate the error using a *Loss Fucntion* which will trigger an adjustment of the neurons weight which trigger their activation. As iterations pass, the network will adjust their weight to minimize the error learning patterns to solve the problem.\n",
    "\n",
    "In order to avoid overfitting, which means that the model \"memorizes\" the training data and does not perform well with new data, we randomly drop some neurons on each iteration, so the model can generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to install Spacy first:\n",
    "```\n",
    "pip install -U pip setuptools wheel\n",
    "pip install -U spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 1984.1658156155754}\n",
      "{'ner': 109.73926401266718}\n",
      "{'ner': 138.12986747484507}\n",
      "{'ner': 47.588300116433004}\n",
      "{'ner': 2.0419946271741405}\n",
      "{'ner': 3.7440482430942508}\n",
      "{'ner': 2.012700471865181}\n",
      "{'ner': 2.051291773717853}\n",
      "{'ner': 0.0007268571710379556}\n",
      "{'ner': 1.8225483010250167}\n",
      "{'ner': 0.0028021886504119237}\n",
      "{'ner': 0.0030751793809788803}\n",
      "{'ner': 1.851928768298534e-06}\n",
      "{'ner': 1.3330685327512708}\n",
      "{'ner': 0.0025945839101430344}\n",
      "{'ner': 0.0010146719511195867}\n",
      "{'ner': 0.0001327180884835861}\n",
      "{'ner': 0.01385305647296808}\n",
      "{'ner': 0.00010323189421863507}\n",
      "{'ner': 7.754888536541881e-09}\n",
      "{'ner': 1.665324719642864e-10}\n",
      "{'ner': 2.2762587873646342e-07}\n",
      "{'ner': 1.0154709520117594e-08}\n",
      "{'ner': 2.1325194765755028e-10}\n",
      "{'ner': 2.7548444297135507e-09}\n",
      "{'ner': 2.2013025419373184e-08}\n",
      "{'ner': 6.319800208021556e-10}\n",
      "{'ner': 6.278292340971489e-09}\n",
      "{'ner': 2.2878875866347553e-11}\n",
      "{'ner': 2.4229452172145967e-08}\n",
      "{'ner': 1.2993179705777092e-10}\n",
      "{'ner': 3.8404045014699504e-08}\n",
      "{'ner': 2.593142834269671e-09}\n",
      "{'ner': 2.1307460434300294e-10}\n",
      "{'ner': 1.6702810563580654e-10}\n",
      "{'ner': 3.02607680600006e-10}\n",
      "{'ner': 1.0873492037023543e-09}\n",
      "{'ner': 0.16964230013965584}\n",
      "{'ner': 1.9999901689083854}\n",
      "{'ner': 1.4198542483620745e-08}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "ner.add_label(\"OIL\")\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 40 iterations\n",
    "for itn in range(40):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses, drop=0.3)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the error decreasing as iterations go by, note that some times it may increase due to the dropout setting.\n",
    "\n",
    "#### Save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"oil.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Let's test the model.  For this we use displacy which will display the entities in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "example = \"service postings marathon petroleum co said it reduced the contract price it will pay for all grades of service oil one dlr a barrel effective today the decrease brings marathon s posted price for both west texas intermediate and west texas sour to dlrs a bbl the south louisiana sweet grade of service was reduced to dlrs a bbl the company last changed its service postings on jan reuter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Service postings marathon \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    petroleum\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">OIL</span>\n",
       "</mark>\n",
       " co said it reduced the contract price it will pay for all grades of service \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    oil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">OIL</span>\n",
       "</mark>\n",
       " one dlr a barrel effective today the decrease brings marathon s posted price for both west texas intermediate and west texas sour to dlrs a bbl the south louisiana sweet grade of service was reduced to dlrs a bbl the company last changed its service postings on jan reuter</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(example)\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We have shown how to label data with **Doccano** and create a custom model with **Spacy**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Matching\n",
    "\n",
    "The second approach is to use pattern matching to look for certain keywords and patterns in the text. \n",
    "\n",
    "**Spacy** provides matchers which can be easily used to look for specific substrings, digits, etc. We can also set rules based on the part-of-speech tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['petroleum', 'oil']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(example)\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"OIL_PATTERN\", None, [{\"LOWER\": \"oil\"}], [{\"LOWER\": \"petroleum\"}])\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how we also found the right tag, but in this case typos or similar words are not detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have seen to different approaches used for entity recognition. \n",
    "\n",
    "**Pattern Matching** can be used in the following use cases:\n",
    "- Low cardinality attributes\n",
    "- Common patterns such dates, quantities, numbers, etc.\n",
    "- Patterns occuring in certain parts of the speech\n",
    "- When typos are not expected\n",
    "- Structured data\n",
    "\n",
    "\n",
    "\n",
    "**Statistical Models** are great to learn complex patterns in the data and can \"guess\" and categorize data never seem before. Use cases:\n",
    "- High Cardinality attributes\n",
    "- You need to deal with typos (fuzzy matches)\n",
    "- You need to categorize new, never seen data.\n",
    "- Unstructured data\n",
    "\n",
    "These models are much more powerful since they can make decisions on things that were never trained on. It can detect new entities without any code change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
